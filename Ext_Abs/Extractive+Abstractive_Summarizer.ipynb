{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1kB_IUe6aQT",
    "outputId": "31c101c6-7823-48d0-d619-817a8d02290f"
   },
   "outputs": [],
   "source": [
    "# !pip install bert-extractive-summarizer\n",
    "# !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q tensorflow-gpu==2.2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0shdBqkLB-2m"
   },
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a-s3snYDpAV"
   },
   "source": [
    "DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f3DaGukVlAj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "check_path = \"/content/train.csv\"\n",
    "my_file = Path(check_path)\n",
    "flag = 0\n",
    "if flag and not my_file.is_file():\n",
    "    check_path = \"/content/AMICorpusXML/data/ami-summary/abstractive/ES2004a.abssumm.txt\"\n",
    "\n",
    "    my_file = Path(check_path)\n",
    "    if not my_file.is_file():\n",
    "        if not Path(\"/content/AMICorpusXML/data\").is_dir():\n",
    "            ! git clone https://github.com/gcunhase/AMICorpusXML\n",
    "        ! python /content/AMICorpusXML/main_obtain_meeting2summary_data.py --summary_type abstractive\n",
    "    else:\n",
    "        print(\"Data already prepared... Importing\\n\")\n",
    "\n",
    "    val = \"ES2003, ES2011, IS1008, TS3004, TS3006\".split(',')\n",
    "    train = \"\"\"ES2002, ES2005, ES2006, ES2007, ES2008, ES2009, ES2010, ES2012, ES2013, ES2015, \n",
    "                ES2016, IS1000, IS1001, IS1003, IS1004, IS1006, IS1007, TS3005, TS3008, TS3009, TS3010, \n",
    "                TS3011, TS3012\"\"\".split(\",\")\n",
    "    test = \"ES2004, ES2014, IS1009, TS3003, TS3007\".split(\",\")\n",
    "\n",
    "    story_directory = r'/content/AMICorpusXML/data/ami-transcripts-stories/abstractive'\n",
    "    sum_directory = r'/content/AMICorpusXML/data/ami-summary/abstractive'\n",
    "\n",
    "    story_val = []\n",
    "    for filename in os.listdir(story_directory):\n",
    "        if filename.endswith(\".story\"):\n",
    "            for each in val:\n",
    "                if each.strip() in str(filename):\n",
    "                    story_val.append(filename)\n",
    "\n",
    "    def data_read(f1):\n",
    "        with open(f1, 'r') as file:\n",
    "            data1 = file.read().replace('\\n', '')\n",
    "        return data1\n",
    "\n",
    "    val_data = []\n",
    "    val_summ = []\n",
    "    for each in story_val:\n",
    "        a = each.split('.')[0]\n",
    "        story_file = story_directory+'/'+each\n",
    "        summ_file = sum_directory+'/'+a+\".abssumm.txt\"\n",
    "        data = data_read(story_file)\n",
    "        val_data.append(data)\n",
    "        data = data_read(summ_file)\n",
    "        val_summ.append(data)\n",
    "else:\n",
    "    train = pd.read_csv(\"./content/train.csv\", sep='\\t')\n",
    "    train = train.drop(['Unnamed: 0'],axis=1)\n",
    "    test = pd.read_csv(\"./content/test.csv\", sep='\\t')\n",
    "    test = test.drop(['Unnamed: 0'],axis=1)\n",
    "    val = pd.read_csv(\"./content/val.csv\", sep='\\t')\n",
    "    val = val.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "peo1qPL7WDzi",
    "outputId": "6803a1b1-9e55-4594-e5e3-550710dc90dc"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEAcZejLDnFs"
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuQ8ZAwjETsA"
   },
   "source": [
    "## EXTRACTIVE SUMMARY GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkkcauCrZX59"
   },
   "source": [
    "BERTSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtUhV65bGZKz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from summarizer import Summarizer\n",
    "from tqdm import tqdm\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "km0K9T9fujTH"
   },
   "outputs": [],
   "source": [
    "# test = test[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmfbAac0Fbb3",
    "outputId": "9ce80225-b7a9-4399-abe0-8fa7a13cc220",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ext_summary = []\n",
    "# model.eval()\n",
    "for index, row in tqdm(train.iterrows(), ):\n",
    "    input = row['inputs']\n",
    "    target = row['targets']\n",
    "#     print(input)\n",
    "    result = model(input, max_length=512)\n",
    "#     summ = \"\".join(result)\n",
    "    ext_summary.append((result,target))\n",
    "\n",
    "# test['ext_summary'] = ext_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input.split()), len(result.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "a = [train_[i:i+m] for i in range(0,len(train_),m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Um, basically what I'm gonna have to talk to you about today is um component design and it's been brought to my attention that we may be somewhat limited as to what we can do because of what our manufacturer offers, so Basically what I'm gonna be doing is talking to you about that. Um, components of a remote control, okay. Um, and also there's a kinetic energy possibility. And if we do go with the rubber doubled curved case um we'll have to use rubber push buttons because the other buttons aren't compatible with that. And if you were to record if you were to make a video recording you could actually see the light. Um, of course Yeah, just as a fun gimmick. Um, and then on to the circuit board that we're gonna use, also known as the chip. Um, if we do go the lithium battery route then we'll have to go outside our current manufacturer. It is the new it would be in a class of its own. We could initially go with what we have and if we can find them cheaper later on Yeah. Doesn't have to be out taking a sunbath for a few hours a day or anything. If, if we're not going the touch-screen route then we can um just incorporate maybe something that folds out like what you often see on these kinds of remotes is the most basic functions up here and something that slides down to reveal the you know more complicated things. Um, another concept is what uh Apple has come up with, the spinning wheel with uh L_C_ display like on the uh iPod which I am sure most of you know about. Uh the jumbo universal remote control is almost impossible to misplace or lose. Um, again probably not what we're going for so I I mean my ideas here and kind of where I think we're heading is something slightly larger than a regular iPod uh with a hard cla c uh plastic casing although I think some of the suggestions we've come up with are definitely uh very good ideas. Oh you guys are always the dampers on these projects. Where do you guys come up with these numbers? I think it's all about following Apple's lead on a lot of these things. Think then we're hitting our cost issue again. And again copying iMac's kind of for iPod Mac Apple's uh colour scheme. I think that goes against the whole fancy something, a new line, but worth a shot. I think we'd have to decide between 'em definitely. Course, maybe they hadn't thought of this whole touch screen option, but definitely we know the market is there for voice recognition so to say we have the technology and we're not gonna use it even though we know it'll sell is a call I don't think I can give the highs ups. Like really I can't go in and say no we're gonna just ignore everything we know. So and when are we gonna have basic prototypes coming up next that's you guys's next step right? Well and do we wanna consider like an iPod screen which isn't a touch screen but you're still scrolling through menu options, in p True, we're still not making it easier then. Oh it wasn't in the way but yeah, whatever. Right so um, apologies for the last meeting, it was brought to my attention that I did not make the roles clear enough, um, so I will attempt to do so more accurately in this particular meeting. So, without th further ado, whoever wants to go first is free to. Yeah, it's like, yep it's ubiquitous isn't it? Right so, good to know all that stuff, thanks guys, um. Now we kind of have to come to some decisions, um, I figure we can just go down the line and all three of us can have a chat about it. Based on what Nathan presented as far as the um various costs and benefits um I think, I dunno, what do you guys think about the touch screen at this point? ' So From the board, um, well That's true, I mean And that's to be fair the um the per cent of the market we're not going for mass any you know, mass sales anyway, we're gonna make I mean we we're not talking about selling eight zillion of these things, we just couldn't, not for twenty-five Euros, so we could probably maybe shrink the profit margins rather than selling for twenty five, sell 'em for thirty, but that's something that we can have finance deal with. You know, you can't you can't have all three. Otherwise, yeah, we just it just becomes cost prohibitive. Is it cheaper to do the V_R_ or to do the uh touch screen? We will omit the touch screen in favour of voice recognition. Would the solar power be enough to fuel a voice recognition? We'll have more of an idea when the prototype have more of a we'll have more of an idea later on. We've already kind of covered this as well. So that's what to start with for now, is that alright, you guys feel clear about this?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    title = [j[1] for j in i]\n",
    "    body = [j[0] for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The project manager opened the meeting and read the minutes of the previous meeting. The industrial designer and user interface designer presented the prototype they created, which was designed to look like a banana. The marketing expert conducted an evaluation of the prototype. The team found that, although the overall design of the prototype was attractive, its yellow color was ugly. The team rated the prototype highly on its ease of use and felt that its yellow color and shape detracted slightly from its ability to be misplaced and that a feature which causes the remote to make noise based on its proximity to a television needed to be added. The team thought the prototype was fashionable and not technologically innovative or spongy. The project manager led the team in calculating the production costs of the remote and ensuring that they aligned with the project budget. The costs were over budget, so the team opted to exclude the LCD from their design to meet their budget. The team conducted an evaluation of the project process and found that they performed well and were somewhat satisfied by the resources available to them. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 93)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a), len(a)*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('../Ext_Abs/train.txt', \"r\") as f:\n",
    "    train_ = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('train.txt', \"w\") as f:\n",
    "    f.write(json.dumps(ext_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "NUlJy5mdZOnx",
    "outputId": "b57db842-4d42-4857-c7f5-f1097c313bc9"
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_ext.csv', sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0fZ2fVKEf-c"
   },
   "source": [
    "## EXTRACTIVE TO ABSTRACTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSnDiccnvKJw"
   },
   "source": [
    "GPT2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5wvRbcsvv6u",
    "outputId": "159c0aba-1c7c-4126-8676-d9f90c43a401",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "modelgpt2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KNdTmgfv1h1",
    "outputId": "9e94471e-a345-4933-c834-e379095252f4"
   },
   "outputs": [],
   "source": [
    "abs_summary = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    input = row['ext_summary']\n",
    "#     print(input)\n",
    "    input_ids = tokenizer.encode(input, return_tensors='tf')\n",
    "    summ = modelgpt2.generate(input_ids, max_length=200)\n",
    "    summ_decoded = tokenizer.decode(summ[0], skip_special_tokens=True)\n",
    "    abs_summary.append(summ_decoded)\n",
    "\n",
    "test['abs_summary'] = abs_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZCyNV5Zco1v"
   },
   "source": [
    "BEAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXte8_qewVTP",
    "outputId": "da68a9b3-e9d5-4253-e794-5bb892e5be95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs_summary = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    input = row['ext_summary']\n",
    "#     print(input)\n",
    "    input_ids = tokenizer.encode(input, return_tensors='tf')\n",
    "    beam_output = modelgpt2.generate(\n",
    "        input_ids, \n",
    "        max_length=200, \n",
    "        num_beams=5, \n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summ_decoded =tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "    abs_summary.append(summ_decoded)\n",
    "\n",
    "test['beam_abs_summary'] = abs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLz4BTW8wV02",
    "outputId": "8dd4f82a-60ad-4088-cd16-568b9acf51a9"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYUMkO5F-J-X"
   },
   "source": [
    "TOP P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er34eKqh-JbS",
    "outputId": "951525fb-bd98-49ce-b1cd-a3b0e9274bf7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs_summary = []\n",
    "\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    input = row['ext_summary']\n",
    "#     print(input)\n",
    "    input_ids = tokenizer.encode(input, return_tensors='tf')\n",
    "\n",
    "    # set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "    tf.random.set_seed(0)\n",
    "    # deactivate top_k sampling and sample only from 92% most likely words\n",
    "    sample_output = modelgpt2.generate(\n",
    "        input_ids, \n",
    "        do_sample=True, \n",
    "        max_length=200, \n",
    "        top_p=0.92, \n",
    "        top_k=0\n",
    "    )\n",
    "    summ_decoded = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
    "    abs_summary.append(summ_decoded)\n",
    "test['top_P_abs_summary'] = abs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "7jBSQTDW-vHF",
    "outputId": "d139a874-e00b-4c1e-a1c9-ded20581d1db"
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_ext.csv', sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HvmxeiF-IGW"
   },
   "source": [
    "ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brxNWrrg6v6G",
    "outputId": "1e48e8ff-8d52-4c2f-ccac-c2cc88a970c5"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wddIBwt8ofR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggsTtYgH7Znq"
   },
   "outputs": [],
   "source": [
    "def rogue_sc(b, a):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(b,a)\n",
    "    # print(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "pZ3KI-Mh9Dri",
    "outputId": "5b4c1ea4-8443-400e-cc8b-be8b6eb7d8e7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rouge1 = []\n",
    "rouge2 = []\n",
    "# word_capt = []\n",
    "for index, row in test.iterrows():\n",
    "    rouge1.append(rogue_sc(row['targets'], row['top_P_abs_summary'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['targets'], row['top_P_abs_summary'])['rouge2'][1])\n",
    "    # word_capt.append(rogue_sc(row['targets'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"------ top_P_abs_summary-------\")\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    rouge1.append(rogue_sc(row['targets'], row['ext_summary'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['targets'], row['ext_summary'])['rouge2'][1])\n",
    "    # word_capt.append(rogue_sc(row['targets'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"------ Extractive_summary-------\")\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))\n",
    "\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    rouge1.append(rogue_sc(row['targets'], row['beam_abs_summary'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['targets'], row['beam_abs_summary'])['rouge2'][1])\n",
    "    # word_capt.append(rogue_sc(row['targets'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"------ Beams_summary-------\")\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))\n",
    "\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    rouge1.append(rogue_sc(row['targets'], row['abs_summary'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['targets'], row['abs_summary'])['rouge2'][1])\n",
    "    # word_capt.append(rogue_sc(row['targets'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"------ Beams_summary-------\")\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "La2trJ5x_I2B"
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_ext.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test_ext.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extractive+Abstractive Summarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

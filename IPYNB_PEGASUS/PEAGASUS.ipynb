{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PEAGASUS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IY_YZS-NVqm",
        "outputId": "975fc81d-1407-4f7c-928e-4bdc804516ee"
      },
      "source": [
        "!pip install transformers==3.5.0\n",
        "!pip install torch==1.7.0\n",
        "!pip install rouge-score\n",
        "\n",
        "from transformers import PegasusTokenizer,PegasusForConditionalGeneration\n",
        "from rouge_score import rouge_scorer\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.12.4)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (20.4)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2020.11.8)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.0) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.0) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5ccbd950b3427b236eff800830340442cf52cd6a2f8750f979097cbfb65107ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0) (1.18.5)\n",
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr3LzFBrGuM-",
        "outputId": "927bba91-e372-4e1b-be68-a2b7e0a269c0"
      },
      "source": [
        "\n",
        "check_path = \"/content/AMICorpusXML/data/ami-summary/abstractive/ES2004a.abssumm.txt\"\n",
        "from pathlib import Path\n",
        "\n",
        "my_file = Path(check_path)\n",
        "if not my_file.is_file():\n",
        "    if not Path(\"/content/AMICorpusXML/data\").is_dir():\n",
        "        ! git clone https://github.com/gcunhase/AMICorpusXML\n",
        "    ! python /content/AMICorpusXML/main_obtain_meeting2summary_data.py --summary_type abstractive\n",
        "else:\n",
        "    print(\"Data already prepared... Importing\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AMICorpusXML'...\n",
            "remote: Enumerating objects: 9453, done.\u001b[K\n",
            "remote: Counting objects: 100% (9453/9453), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9271/9271), done.\u001b[K\n",
            "remote: Total 9664 (delta 196), reused 9426 (delta 170), pack-reused 211\u001b[K\n",
            "Receiving objects: 100% (9664/9664), 9.67 MiB | 13.87 MiB/s, done.\n",
            "Resolving deltas: 100% (224/224), done.\n",
            "Downloading AMI Corpus to: data/ami_public_manual_1.6.2\n",
            "Extracting speaker transcripts to: data/ami-transcripts-speaker/\n",
            "Transcripts: 687\n",
            "\n",
            "Saving transcripts in: data/ami-transcripts/\n",
            "Number of meetings: 171\n",
            "\n",
            "Obtaining abstractive summaries to: data/ami-summary/\n",
            "Make .story files\n",
            "Make .story files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TGWmiqXGJZL2",
        "outputId": "3c83dc81-6cf8-4742-e66f-486b6f059d64"
      },
      "source": [
        "# taking same split to make easy comparision\n",
        "# data split knowledge: http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml\n",
        "# 5 x 4 = 20 \n",
        "test = \"ES2004, ES2014, IS1009, TS3003, TS3007\".split(',')\n",
        "\n",
        "val = \"ES2003, ES2011, IS1008, TS3004, TS3006\".split(',')\n",
        "train = \"\"\"ES2002, ES2005, ES2006, ES2007, ES2008, ES2009, ES2010, ES2012, ES2013, ES2015, \n",
        "            ES2016, IS1000, IS1001, IS1003, IS1004, IS1006, IS1007, TS3005, TS3008, TS3009, TS3010, \n",
        "            TS3011, TS3012\"\"\".split(\",\")\n",
        "\n",
        "story = []\n",
        "story_directory = r'/content/AMICorpusXML/data/ami-transcripts-stories/abstractive'\n",
        "for filename in os.listdir(story_directory):\n",
        "    if filename.endswith(\".story\"):\n",
        "        for each in test:\n",
        "            if each.strip() in str(filename):\n",
        "                story.append(filename)\n",
        "     \n",
        "summary = []\n",
        "sum_directory = r'/content/AMICorpusXML/data/ami-summary/abstractive'\n",
        "for filename in os.listdir(sum_directory):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        for each in test:\n",
        "            if each.strip() in str(filename):\n",
        "                summary.append(filename)\n",
        "\n",
        "def prepare_model(model_name = 'google/pegasus-xsum'):\n",
        "    print(\"----------------- Preparing Model -----------------\")\n",
        "    \n",
        "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "    print(\"----------------- Model Prepared -----------------\")\n",
        "    return tokenizer, model, torch_device\n",
        "\n",
        "def test_model(src_text, tokenizer, model):\n",
        "    print(\"\\nNew Testing started...\")\n",
        "    batch = tokenizer.prepare_seq2seq_batch(src_text, padding='max_length').to(torch_device)\n",
        "    translated = model.generate(**batch)\n",
        "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "    return tgt_text\n",
        "\n",
        "def data_from_file(f1,f2):\n",
        "    with open(f1, 'r') as file:\n",
        "        data1 = file.read().replace('\\n', '')\n",
        "    with open(f2, 'r') as file:\n",
        "        data2 = file.read().replace('\\n', '')\n",
        "    return data1, data2\n",
        "\n",
        "df = pd.DataFrame()\n",
        "st, sums_pred, sums_ann = [], [], []\n",
        "\n",
        "# remove later\n",
        "# flag = 0\n",
        "\n",
        "tokenizer, model, torch_device = prepare_model()\n",
        "for each in tqdm(story):\n",
        "    a = each.split('.')[0]\n",
        "    story_file = story_directory+'/'+each\n",
        "    summ_file = sum_directory+'/'+a+\".abssumm.txt\"\n",
        "    story_file, summ_file = data_from_file(story_file, summ_file)\n",
        "    st.append(story_file)\n",
        "    src_text = [story_file.replace('\\n',' ')]\n",
        "    result = test_model(src_text, tokenizer, model)\n",
        "    sums_pred.append(result[0])\n",
        "    sums_ann.append(summ_file)\n",
        "\n",
        "    # flag+=1\n",
        "    # if flag >=2: break\n",
        "\n",
        "df['stories'] = st\n",
        "df['summaries'] = sums_pred\n",
        "df['Summary annotated'] = sums_ann\n",
        "df.to_csv('summary_df.csv')\n",
        "display(df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 1/20 [00:21<06:41, 21.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 2/20 [00:43<06:24, 21.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 3/20 [01:03<05:57, 21.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 4/20 [01:45<07:17, 27.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 5/20 [02:06<06:24, 25.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 6/20 [02:33<06:03, 25.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 7/20 [02:54<05:16, 24.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 8/20 [03:15<04:41, 23.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 9/20 [03:53<05:06, 27.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 10/20 [04:25<04:51, 29.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 11/20 [04:52<04:15, 28.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 12/20 [05:19<03:44, 28.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 13/20 [05:45<03:11, 27.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 14/20 [06:06<02:32, 25.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 15/20 [06:28<02:01, 24.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 16/20 [06:57<01:43, 25.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 17/20 [07:35<01:28, 29.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 18/20 [07:54<00:52, 26.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 19/20 [08:19<00:25, 25.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "New Testing started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [08:48<00:00, 26.42s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stories</th>\n",
              "      <th>summaries</th>\n",
              "      <th>Summary annotated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello. Hi. Yeah. It's too beautiful. A minute ...</td>\n",
              "      <td>Janus, welcome back to the functional design m...</td>\n",
              "      <td>When this functional design meeting opens the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Well hi everyone again. Um like before we uh I...</td>\n",
              "      <td>This is the meeting where we discuss the desig...</td>\n",
              "      <td>The project manager opens the meeting by going...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wouldn't wanna be Project Manager. Uh, what we...</td>\n",
              "      <td>Let's start with the presentation.</td>\n",
              "      <td>The project manager opened the meeting and wen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Okay. Yeah, my name is Francina. And I'm uh an...</td>\n",
              "      <td>In our series of letters from Australian stude...</td>\n",
              "      <td>The meeting opens with the group doing introdu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Okay, is everybody ready? Mm-hmm. Um I take it...</td>\n",
              "      <td>Mm-hmm.</td>\n",
              "      <td>The meeting begins and the marketing expert st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             stories  ...                                  Summary annotated\n",
              "0  Hello. Hi. Yeah. It's too beautiful. A minute ...  ...  When this functional design meeting opens the ...\n",
              "1  Well hi everyone again. Um like before we uh I...  ...  The project manager opens the meeting by going...\n",
              "2  Wouldn't wanna be Project Manager. Uh, what we...  ...  The project manager opened the meeting and wen...\n",
              "3  Okay. Yeah, my name is Francina. And I'm uh an...  ...  The meeting opens with the group doing introdu...\n",
              "4  Okay, is everybody ready? Mm-hmm. Um I take it...  ...  The meeting begins and the marketing expert st...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W8qnUFOhQ03",
        "outputId": "6087fcb1-3ebe-425a-a5e0-e0e63a1e9a99"
      },
      "source": [
        "# R1 and R2 for a sample summary \n",
        "a = df[\"stories\"][0]\n",
        "b = df[\"summaries\"][0]\n",
        "c = df[\"Summary annotated\"][0]\n",
        "\n",
        "def rogue_sc(b, a):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
        "    scores = scorer.score(b,a)\n",
        "    return scores\n",
        "\n",
        "scores = rogue_sc(b,a)\n",
        "print(\"Word Capture: \", scores['rouge1'][1])\n",
        "scores = rogue_sc(b,c)\n",
        "print(\"ROUGE-1 Score: \", scores['rouge1'][1])\n",
        "print(\"ROUGE-2 Score: \", scores['rouge2'][1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word Capture:  1.0\n",
            "ROUGE-1 Score:  0.625\n",
            "ROUGE-2 Score:  0.2857142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hornQ9aehRqL",
        "outputId": "e799c284-5a74-4a01-aba2-1c62e8dfb897"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "rouge1 = []\n",
        "rouge2 = []\n",
        "word_capt = []\n",
        "for index, row in df.iterrows():\n",
        "    rouge1.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
        "    rouge2.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge2'][1])\n",
        "    word_capt.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
        "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
        "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Rouge1 Score:  35.14517243762526\n",
            "Average Rouge2 Score:  9.775370970492922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEyFgXfmhb7I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
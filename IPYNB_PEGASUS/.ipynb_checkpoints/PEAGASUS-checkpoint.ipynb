{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hemant/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer,PegasusForConditionalGeneration\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lr3LzFBrGuM-",
    "outputId": "927bba91-e372-4e1b-be68-a2b7e0a269c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already prepared... Importing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_path = \"AMICorpusXML/data/ami-summary/abstractive/ES2004a.abssumm.txt\"\n",
    "from pathlib import Path\n",
    "\n",
    "my_file = Path(check_path)\n",
    "if not my_file.is_file():\n",
    "    if not Path(\"AMICorpusXML/data\").is_dir():\n",
    "        ! git clone https://github.com/gcunhase/AMICorpusXML\n",
    "    ! python /content/AMICorpusXML/main_obtain_meeting2summary_data.py --summary_type abstractive\n",
    "else:\n",
    "    print(\"Data already prepared... Importing\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking same split to make easy comparision\n",
    "# data split knowledge: http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml\n",
    "# 5 x 4 = 20 \n",
    "test = \"ES2004, ES2014, IS1009, TS3003, TS3007\".split(',')\n",
    "\n",
    "val = \"ES2003, ES2011, IS1008, TS3004, TS3006\".split(',')\n",
    "train = \"\"\"ES2002, ES2005, ES2006, ES2007, ES2008, ES2009, ES2010, ES2012, ES2013, ES2015, \n",
    "            ES2016, IS1000, IS1001, IS1003, IS1004, IS1006, IS1007, TS3005, TS3008, TS3009, TS3010, \n",
    "            TS3011, TS3012\"\"\".split(\",\")\n",
    "\n",
    "\n",
    "def data_create(path):\n",
    "    story = []\n",
    "    story_directory = r'AMICorpusXML/data/ami-transcripts-stories/abstractive'\n",
    "    for filename in os.listdir(story_directory):\n",
    "        if filename.endswith(\".story\"):\n",
    "            for each in path:\n",
    "                if each.strip() in str(filename):\n",
    "                    story.append(filename)\n",
    "    summary = []\n",
    "    sum_directory = r'AMICorpusXML/data/ami-summary/abstractive'\n",
    "    for filename in os.listdir(sum_directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            for each in path:\n",
    "                if each.strip() in str(filename):\n",
    "                    summary.append(filename)\n",
    "    return [data_from_file(f\"AMICorpusXML/data/ami-transcripts-stories/abstractive/{story[i]}\", f\"AMICorpusXML/data/ami-summary/abstractive/{summary[i]}\") for i in range(len(story))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_name = 'google/pegasus-xsum'):\n",
    "    print(\"----------------- Preparing Model -----------------\")\n",
    "    \n",
    "    torch_device = \"cpu\" #'cuda'if torch.cuda.is_available() else 'cpu'\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "    print(\"----------------- Model Prepared -----------------\")\n",
    "    return tokenizer, model, torch_device\n",
    "\n",
    "def test_model(src_text, tokenizer, model):\n",
    "#     print(\"\\nNew Testing started...\")\n",
    "    batch = tokenizer.prepare_seq2seq_batch(src_text,max_length=512).to(torch_device)\n",
    "    translated = model.generate(**batch)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text\n",
    "\n",
    "def data_from_file(f1,f2):\n",
    "    with open(f1, 'r') as file:\n",
    "        data1 = file.read().replace('\\n', '')\n",
    "    with open(f2, 'r') as file:\n",
    "        data2 = file.read().replace('\\n', '')\n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TGWmiqXGJZL2",
    "outputId": "3c83dc81-6cf8-4742-e66f-486b6f059d64",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# taking same split to make easy comparision\n",
    "# data split knowledge: http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml\n",
    "# 5 x 4 = 20 \n",
    "test = \"ES2004, ES2014, IS1009, TS3003, TS3007\".split(',')\n",
    "\n",
    "val = \"ES2003, ES2011, IS1008, TS3004, TS3006\".split(',')\n",
    "train = \"\"\"ES2002, ES2005, ES2006, ES2007, ES2008, ES2009, ES2010, ES2012, ES2013, ES2015, \n",
    "            ES2016, IS1000, IS1001, IS1003, IS1004, IS1006, IS1007, TS3005, TS3008, TS3009, TS3010, \n",
    "            TS3011, TS3012\"\"\".split(\",\")\n",
    "\n",
    "story = []\n",
    "story_directory = r'AMICorpusXML/data/ami-transcripts-stories/abstractive'\n",
    "for filename in os.listdir(story_directory):\n",
    "    if filename.endswith(\".story\"):\n",
    "        for each in test:\n",
    "            if each.strip() in str(filename):\n",
    "                story.append(filename)\n",
    "     \n",
    "summary = []\n",
    "sum_directory = r'AMICorpusXML/data/ami-summary/abstractive'\n",
    "for filename in os.listdir(sum_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        for each in test:\n",
    "            if each.strip() in str(filename):\n",
    "                summary.append(filename)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "st, sums_pred, sums_ann = [], [], []\n",
    "\n",
    "# remove later\n",
    "# flag = 0\n",
    "\n",
    "tokenizer, model, torch_device = prepare_model()\n",
    "model.eval()\n",
    "for each in tqdm(story):\n",
    "    a = each.split('.')[0]\n",
    "    story_file = story_directory+'/'+each\n",
    "    summ_file = sum_directory+'/'+a+\".abssumm.txt\"\n",
    "    story_file, summ_file = data_from_file(story_file, summ_file)\n",
    "    st.append(story_file)\n",
    "    src_text = [story_file.replace('\\n',' ')]\n",
    "    result = test_model(src_text, tokenizer, model)\n",
    "    sums_pred.append(result[0])\n",
    "    sums_ann.append(summ_file)\n",
    "\n",
    "    # flag+=1\n",
    "    # if flag >=2: break\n",
    "\n",
    "df['stories'] = st\n",
    "df['summaries'] = sums_pred\n",
    "df['Summary annotated'] = sums_ann\n",
    "df.to_csv('summary_df.csv')\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "test# R1 and R2 for a sample summary \n",
    "a = df[\"stories\"][0]\n",
    "b = df[\"summaries\"][0]\n",
    "c = df[\"Summary annotated\"][0]\n",
    "\n",
    "def rogue_sc(b, a):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(b,a)\n",
    "    return scores\n",
    "\n",
    "scores = rogue_sc(b,a)\n",
    "print(\"Word Capture: \", scores['rouge1'][1])\n",
    "scores = rogue_sc(b,c)\n",
    "print(\"ROUGE-1 Score: \", scores['rouge1'][1])\n",
    "print(\"ROUGE-2 Score: \", scores['rouge2'][1])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rouge1 = []\n",
    "rouge2 = []\n",
    "word_capt = []\n",
    "for index, row in df.iterrows():\n",
    "    rouge1.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge2'][1])\n",
    "    word_capt.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6W8qnUFOhQ03",
    "outputId": "6087fcb1-3ebe-425a-a5e0-e0e63a1e9a99"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothed_nll_loss(lprobs, target, epsilon, ignore_index=-100):\n",
    "    \"\"\"From fairseq\"\"\"\n",
    "    if target.dim() == lprobs.dim() - 1:\n",
    "        target = target.unsqueeze(-1)\n",
    "    nll_loss = -lprobs.gather(dim=-1, index=target)\n",
    "    smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
    "    if ignore_index is not None:\n",
    "        pad_mask = target.eq(ignore_index)\n",
    "        nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "        smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "    else:\n",
    "        nll_loss = nll_loss.squeeze(-1)\n",
    "        smooth_loss = smooth_loss.squeeze(-1)\n",
    "\n",
    "    nll_loss = nll_loss.sum()  # mean()? Scared to break other math.\n",
    "    smooth_loss = smooth_loss.sum()\n",
    "    eps_i = epsilon / lprobs.size(-1)\n",
    "    loss = (1.0 - epsilon) * nll_loss + eps_i * smooth_loss\n",
    "    return loss, nll_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 5\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "weight_decay =0.0\n",
    "learning_rate = 1e-4 \n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "t_total = (607276 // 2 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dhak chiki dhak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = data_create(test)\n",
    "train_ = data_create(train)\n",
    "val_ = data_create(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('../Ext_Abs/train.txt', \"r\") as f:\n",
    "    train_ = json.loads(f.read())\n",
    "with open ('../Ext_Abs/val.txt', \"r\") as f:\n",
    "    val_ = json.loads(f.read())\n",
    "with open ('../Ext_Abs/test.txt', \"r\") as f:\n",
    "    test_ = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = []\n",
    "# for i in test_:\n",
    "#     a.append(len(i[0].split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_bart import shift_tokens_right\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'google/pegasus-xsum'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "output_dir = 'data/train/'\n",
    "# tokenizer = PegasusTokenizer.from_pretrained(output_dir)\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(output_dir).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "# optimizer.load_state_dict(torch.load(os.path.join(output_dir, 'optimizer.pt')))\n",
    "# scheduler.load_state_dict(torch.load(os.path.join(output_dir, 'scheduler.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304a00fe003845b388df58c9449f0180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5762.3447265625\n",
      "batch :5Training Loss: 34665.9765625\n",
      "batch :10Training Loss: 60973.2587890625\n",
      "batch :15Training Loss: 87445.72509765625\n",
      "\n",
      "traing loss epoch1:0.09657480260204863\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 2 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034403854ef14c3baa10f88e60e0ae00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5538.08056640625\n",
      "batch :5Training Loss: 33578.0546875\n",
      "batch :10Training Loss: 58904.0166015625\n",
      "batch :15Training Loss: 84664.333984375\n",
      "\n",
      "traing loss epoch2:0.09354297685988217\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 3 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b0e6f8124b4b559df5ba1af7cf2263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5354.88720703125\n",
      "batch :5Training Loss: 32740.16845703125\n",
      "batch :10Training Loss: 57423.606201171875\n",
      "batch :15Training Loss: 82676.91577148438\n",
      "\n",
      "traing loss epoch3:0.09137823601581277\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 4 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c7e85ad84b4bf78123d7e92924ce53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5244.201171875\n",
      "batch :5Training Loss: 32252.03857421875\n",
      "batch :10Training Loss: 56605.6376953125\n",
      "batch :15Training Loss: 81414.890625\n",
      "\n",
      "traing loss epoch4:0.09006228567908095\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 5 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78500535365944128bf86abeb763624b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5185.36328125\n",
      "batch :5Training Loss: 31598.72705078125\n",
      "batch :10Training Loss: 55614.173828125\n",
      "batch :15Training Loss: 80028.02807617188\n",
      "\n",
      "traing loss epoch5:0.08857992502960294\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 6 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268ca22038974b77a4d5e7edf79e76aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5115.3876953125\n",
      "batch :5Training Loss: 31132.8544921875\n",
      "batch :10Training Loss: 54670.0537109375\n",
      "batch :15Training Loss: 78763.92041015625\n",
      "\n",
      "traing loss epoch6:0.08717159585949111\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 7 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d22f3aa7af446f9b58af1b34f6a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 5010.74658203125\n",
      "batch :5Training Loss: 30629.4287109375\n",
      "batch :10Training Loss: 54152.1787109375\n",
      "batch :15Training Loss: 77828.37426757812\n",
      "\n",
      "traing loss epoch7:0.08614715759742979\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 8 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24bbc884a5d42afbb9c29002e870c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4981.01953125\n",
      "batch :5Training Loss: 30401.7705078125\n",
      "batch :10Training Loss: 53492.863525390625\n",
      "batch :15Training Loss: 77098.34375\n",
      "\n",
      "traing loss epoch8:0.08524693280130821\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 9 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e838c9b0cc24d50b76e8936fc7e984a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4892.6591796875\n",
      "batch :5Training Loss: 30006.0908203125\n",
      "batch :10Training Loss: 52775.234130859375\n",
      "batch :15Training Loss: 76097.70141601562\n",
      "\n",
      "traing loss epoch9:0.08417563576458631\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 10 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d36c4ae2d254bffa84734a705cda03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4863.634765625\n",
      "batch :5Training Loss: 29891.20263671875\n",
      "batch :10Training Loss: 52635.251220703125\n",
      "batch :15Training Loss: 75842.48291015625\n",
      "\n",
      "traing loss epoch10:0.0837625662847207\n",
      "time : 0:00:09\n",
      "\n",
      "======== Epoch 11 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a166613f112e4f5f91f06b97adc116ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4835.15625\n",
      "batch :5Training Loss: 29474.71728515625\n",
      "batch :10Training Loss: 51876.861328125\n",
      "batch :15Training Loss: 74626.82006835938\n",
      "\n",
      "traing loss epoch11:0.08255700693373369\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 12 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed94712426c24ea8b2a96ab91424c9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4730.8974609375\n",
      "batch :5Training Loss: 29179.34375\n",
      "batch :10Training Loss: 51274.4013671875\n",
      "batch :15Training Loss: 74011.99340820312\n",
      "\n",
      "traing loss epoch12:0.08181841135518197\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 13 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da02ca207a3e4dd1ada6a586d8e60c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4825.869140625\n",
      "batch :5Training Loss: 28926.7607421875\n",
      "batch :10Training Loss: 51033.72119140625\n",
      "batch :15Training Loss: 73382.853515625\n",
      "\n",
      "traing loss epoch13:0.08115928969496675\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 14 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0250fa01bbce4de49e370dea3d3e7838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4648.9052734375\n",
      "batch :5Training Loss: 28573.6865234375\n",
      "batch :10Training Loss: 50389.904052734375\n",
      "batch :15Training Loss: 72581.09594726562\n",
      "\n",
      "traing loss epoch14:0.08031526286068236\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 15 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b46c1e51eb9449d879acf5b3208c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4654.5576171875\n",
      "batch :5Training Loss: 28583.21337890625\n",
      "batch :10Training Loss: 50462.346435546875\n",
      "batch :15Training Loss: 72679.85473632812\n",
      "\n",
      "traing loss epoch15:0.080377525347433\n",
      "time : 0:00:09\n",
      "\n",
      "======== Epoch 16 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d65367e36a74dab9540bc593b84132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4614.97021484375\n",
      "batch :5Training Loss: 28264.1484375\n",
      "batch :10Training Loss: 49738.116943359375\n",
      "batch :15Training Loss: 71835.20336914062\n",
      "\n",
      "traing loss epoch16:0.07947009278667831\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 17 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10c9aa7a9d74e36991436d74f5deb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4654.1552734375\n",
      "batch :5Training Loss: 28284.93798828125\n",
      "batch :10Training Loss: 49697.312255859375\n",
      "batch :15Training Loss: 71537.18530273438\n",
      "\n",
      "traing loss epoch17:0.07903427721515151\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 18 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4b9c089e6c4916aa36cbe8a0375e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4541.42333984375\n",
      "batch :5Training Loss: 27935.94091796875\n",
      "batch :10Training Loss: 49112.7412109375\n",
      "batch :15Training Loss: 70902.1455078125\n",
      "\n",
      "traing loss epoch18:0.07838507501496055\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 19 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a248df802f049b3b36003ce5c19a42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4491.43408203125\n",
      "batch :5Training Loss: 27714.19580078125\n",
      "batch :10Training Loss: 48797.51806640625\n",
      "batch :15Training Loss: 70405.1123046875\n",
      "\n",
      "traing loss epoch19:0.07782453701920367\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 20 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a50fe505de841eea7a9ef9fce9700c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4541.02587890625\n",
      "batch :5Training Loss: 27697.63818359375\n",
      "batch :10Training Loss: 48734.48828125\n",
      "batch :15Training Loss: 70344.49291992188\n",
      "\n",
      "traing loss epoch20:0.07773870692961259\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 21 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691fc8873ff74f8b874f1099704419a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4443.9384765625\n",
      "batch :5Training Loss: 27475.44482421875\n",
      "batch :10Training Loss: 48371.705078125\n",
      "batch :15Training Loss: 69620.21215820312\n",
      "\n",
      "traing loss epoch21:0.07696624646041926\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 22 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad21ac94841440ab8cac2f607fcb7262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4369.54296875\n",
      "batch :5Training Loss: 27270.0478515625\n",
      "batch :10Training Loss: 47992.109619140625\n",
      "batch :15Training Loss: 69188.76733398438\n",
      "\n",
      "traing loss epoch22:0.07646701168931358\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 23 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1e6c6eb2c646e4a07b7308a87dd746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4404.02783203125\n",
      "batch :5Training Loss: 27055.865234375\n",
      "batch :10Training Loss: 47676.2529296875\n",
      "batch :15Training Loss: 68716.13940429688\n",
      "\n",
      "traing loss epoch23:0.07602352341476111\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 24 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51055ad58106448fa764a27383223ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4397.94287109375\n",
      "batch :5Training Loss: 27009.33740234375\n",
      "batch :10Training Loss: 47479.69140625\n",
      "batch :15Training Loss: 68343.76196289062\n",
      "\n",
      "traing loss epoch24:0.07551786499071057\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 25 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a817875ee4bb4e7aa8e39d07c6ab541a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4363.876953125\n",
      "batch :5Training Loss: 26917.572265625\n",
      "batch :10Training Loss: 47155.98291015625\n",
      "batch :15Training Loss: 67971.34228515625\n",
      "\n",
      "traing loss epoch25:0.07514401700746359\n",
      "time : 0:00:09\n",
      "\n",
      "======== Epoch 26 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa4eb891a944227a0260fa161f3f386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4350.82861328125\n",
      "batch :5Training Loss: 26807.54736328125\n",
      "batch :10Training Loss: 46945.8544921875\n",
      "batch :15Training Loss: 67615.15673828125\n",
      "\n",
      "traing loss epoch26:0.07479517209385532\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 27 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67afa79ada9b4feda0050e3bafb67a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4322.34375\n",
      "batch :5Training Loss: 26608.0205078125\n",
      "batch :10Training Loss: 46603.775146484375\n",
      "batch :15Training Loss: 67167.71142578125\n",
      "\n",
      "traing loss epoch27:0.07427816594412646\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 28 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e23ff19365f466a89c30894c5ff6658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4242.17529296875\n",
      "batch :5Training Loss: 26464.769775390625\n",
      "batch :10Training Loss: 46447.750244140625\n",
      "batch :15Training Loss: 66840.93090820312\n",
      "\n",
      "traing loss epoch28:0.07393435056517032\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 29 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f226f50f4faf489f862d685415376d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4174.8408203125\n",
      "batch :5Training Loss: 26223.51708984375\n",
      "batch :10Training Loss: 46075.807861328125\n",
      "batch :15Training Loss: 66447.26342773438\n",
      "\n",
      "traing loss epoch29:0.07343781610700204\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 30 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227da62a6b144e3c80cc03432d808b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4289.69677734375\n",
      "batch :5Training Loss: 26064.641845703125\n",
      "batch :10Training Loss: 45869.6552734375\n",
      "batch :15Training Loss: 66106.96533203125\n",
      "\n",
      "traing loss epoch30:0.07306122843681939\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 31 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c9cebcbe67454d8cb389a325041340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4258.25341796875\n",
      "batch :5Training Loss: 26015.8173828125\n",
      "batch :10Training Loss: 45644.163330078125\n",
      "batch :15Training Loss: 65697.91650390625\n",
      "\n",
      "traing loss epoch31:0.07268916029767118\n",
      "time : 0:00:08\n",
      "\n",
      "======== Epoch 32 ========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f89ee69a1f044419ecaa465cead469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :0Training Loss: 4165.14990234375\n",
      "batch :5Training Loss: 25835.055419921875\n",
      "batch :10Training Loss: 45480.857421875\n",
      "batch :15Training Loss: 65514.73193359375\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(model.parameters()):\n",
    "    if i == 400: break\n",
    "    b.requires_grad = False\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "epochs = 100\n",
    "m = []\n",
    "batch_size = 5\n",
    "train_loader = [train_[i:i+batch_size] for i in range(0,len(train_),batch_size)]\n",
    "for epoc in range(epochs):\n",
    "  t0 = time.time()\n",
    "  print(\"\")\n",
    "  print('======== Epoch {} ========'.format(epoc+1))\n",
    "  model.train()\n",
    "  total_train_loss = 0\n",
    "  for i,batch in tqdm(enumerate(train_loader)):\n",
    "    title = [j[1] for j in batch]\n",
    "    body = [j[0] for j in batch]\n",
    "    \n",
    "    batch_tokens = tokenizer.prepare_seq2seq_batch(body,title,max_length=512,max_target_length=202,padding='longest').to(device)\n",
    "    m.append(batch_tokens)\n",
    "    decoder_input_ids = shift_tokens_right(batch_tokens['labels'], pad_token_id)\n",
    "    outputs = model(batch_tokens['input_ids'], attention_mask=batch_tokens['attention_mask'], decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "    lprobs = torch.nn.functional.log_softmax(lm_logits, dim=-1)\n",
    "    loss, nll_loss = label_smoothed_nll_loss(\n",
    "                lprobs, batch_tokens['labels'],0.1, ignore_index=pad_token_id\n",
    "            )\n",
    "    total_train_loss += loss.item()\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if i%5 == 0:\n",
    "      print(\"batch :\" + str(i)+ \"Training Loss: \" +str(total_train_loss))\n",
    "    if (i+1) % 10000 == 0:\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(output_dir)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        torch.save(optimizer.state_dict(), os.path.join(output_dir, 'optimizer.pt'))\n",
    "        torch.save(scheduler.state_dict(), os.path.join(output_dir, 'scheduler.pt')) \n",
    "  training_time = format_time(time.time() - t0)\n",
    "  avg_train_loss = total_train_loss / 1050994\n",
    "  print(\"traing loss epoch\"+str(epoc+1)+\":\"+str(avg_train_loss))\n",
    "  print(\"time : {}\".format(training_time))\n",
    "  \n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "torch.save(optimizer.state_dict(), os.path.join(output_dir, 'optimizer.pt'))\n",
    "torch.save(scheduler.state_dict(), os.path.join(output_dir, 'scheduler.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44acd2e2e9ce4b6c8456371a460ba41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stories</th>\n",
       "      <th>summaries</th>\n",
       "      <th>Summary annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay. About the components design. Um for the ...</td>\n",
       "      <td>The design of the docking station, the energy ...</td>\n",
       "      <td>The project manager opened the meeting and rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okay. Everybody found his place again? Yeah? T...</td>\n",
       "      <td>We're going to start with the functional design.</td>\n",
       "      <td>The project manager stated the agenda and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okay, is everybody ready? Mm-hmm. Um I take it...</td>\n",
       "      <td>We're going to look at some of the things that...</td>\n",
       "      <td>The meeting begins and the marketing expert st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well hi everyone again. Um like before we uh I...</td>\n",
       "      <td>The team has been discussing the design of a n...</td>\n",
       "      <td>The project manager opens the meeting by going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So is Why not save that. Do you want to replac...</td>\n",
       "      <td>We've got the red apple button.</td>\n",
       "      <td>The first prototype for the remote control was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             stories  \\\n",
       "0  Okay. About the components design. Um for the ...   \n",
       "1  Okay. Everybody found his place again? Yeah? T...   \n",
       "2  Okay, is everybody ready? Mm-hmm. Um I take it...   \n",
       "3  Well hi everyone again. Um like before we uh I...   \n",
       "4  So is Why not save that. Do you want to replac...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  The design of the docking station, the energy ...   \n",
       "1   We're going to start with the functional design.   \n",
       "2  We're going to look at some of the things that...   \n",
       "3  The team has been discussing the design of a n...   \n",
       "4                    We've got the red apple button.   \n",
       "\n",
       "                                   Summary annotated  \n",
       "0  The project manager opened the meeting and rec...  \n",
       "1  The project manager stated the agenda and the ...  \n",
       "2  The meeting begins and the marketing expert st...  \n",
       "3  The project manager opens the meeting by going...  \n",
       "4  The first prototype for the remote control was...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Capture:  1.0\n",
      "ROUGE-1 Score:  0.8235294117647058\n",
      "ROUGE-2 Score:  0.3125\n",
      "Average Rouge1 Score:  48.31017980314655\n",
      "Average Rouge2 Score:  14.92631477821695\n"
     ]
    }
   ],
   "source": [
    "# taking same split to make easy comparision\n",
    "# data split knowledge: http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml\n",
    "# 5 x 4 = 20 \n",
    "test = \"ES2004, ES2014, IS1009, TS3003, TS3007\".split(',')\n",
    "\n",
    "val = \"ES2003, ES2011, IS1008, TS3004, TS3006\".split(',')\n",
    "train = \"\"\"ES2002, ES2005, ES2006, ES2007, ES2008, ES2009, ES2010, ES2012, ES2013, ES2015, \n",
    "            ES2016, IS1000, IS1001, IS1003, IS1004, IS1006, IS1007, TS3005, TS3008, TS3009, TS3010, \n",
    "            TS3011, TS3012\"\"\".split(\",\")\n",
    "\n",
    "story = []\n",
    "story_directory = r'AMICorpusXML/data/ami-transcripts-stories/abstractive'\n",
    "for filename in os.listdir(story_directory):\n",
    "    if filename.endswith(\".story\"):\n",
    "        for each in test:\n",
    "            if each.strip() in str(filename):\n",
    "                story.append(filename)\n",
    "     \n",
    "summary = []\n",
    "sum_directory = r'AMICorpusXML/data/ami-summary/abstractive'\n",
    "for filename in os.listdir(sum_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        for each in test:\n",
    "            if each.strip() in str(filename):\n",
    "                summary.append(filename)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "st, sums_pred, sums_ann = [], [], []\n",
    "\n",
    "# remove later\n",
    "# flag = 0\n",
    "\n",
    "# tokenizer, model, torch_device = prepare_model()\n",
    "model.eval()\n",
    "for each in tqdm(story):\n",
    "    a = each.split('.')[0]\n",
    "    story_file = story_directory+'/'+each\n",
    "    summ_file = sum_directory+'/'+a+\".abssumm.txt\"\n",
    "    story_file, summ_file = data_from_file(story_file, summ_file)\n",
    "    st.append(story_file)\n",
    "    src_text = [story_file.replace('\\n',' ')]\n",
    "    result = test_model(src_text, tokenizer, model)\n",
    "    sums_pred.append(result[0])\n",
    "    sums_ann.append(summ_file)\n",
    "\n",
    "    # flag+=1\n",
    "    # if flag >=2: break\n",
    "\n",
    "df['stories'] = st\n",
    "df['summaries'] = sums_pred\n",
    "df['Summary annotated'] = sums_ann\n",
    "df.to_csv('summary_df.csv')\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "test# R1 and R2 for a sample summary \n",
    "a = df[\"stories\"][0]\n",
    "b = df[\"summaries\"][0]\n",
    "c = df[\"Summary annotated\"][0]\n",
    "\n",
    "def rogue_sc(b, a):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(b,a)\n",
    "    return scores\n",
    "\n",
    "scores = rogue_sc(b,a)\n",
    "print(\"Word Capture: \", scores['rouge1'][1])\n",
    "scores = rogue_sc(b,c)\n",
    "print(\"ROUGE-1 Score: \", scores['rouge1'][1])\n",
    "print(\"ROUGE-2 Score: \", scores['rouge2'][1])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rouge1 = []\n",
    "rouge2 = []\n",
    "word_capt = []\n",
    "for index, row in df.iterrows():\n",
    "    rouge1.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
    "    rouge2.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge2'][1])\n",
    "    word_capt.append(rogue_sc(row['summaries'], row['Summary annotated'])['rouge1'][1])\n",
    "print(\"Average Rouge1 Score: \", 100*np.average(np.array(rouge1)))\n",
    "print(\"Average Rouge2 Score: \", 100*np.average(np.array(rouge2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word Capture:  1.0\n",
    "ROUGE-1 Score:  0.8235294117647058\n",
    "ROUGE-2 Score:  0.3125\n",
    "Average Rouge1 Score:  48.31017980314655\n",
    "Average Rouge2 Score:  14.92631477821695\n",
    "\n",
    "Word Capture:  1.0\n",
    "ROUGE-1 Score:  0.75\n",
    "ROUGE-2 Score:  0.36363636363636365\n",
    "Average Rouge1 Score:  60.556109094109885\n",
    "Average Rouge2 Score:  23.351602084656054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stories'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PEAGASUS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
